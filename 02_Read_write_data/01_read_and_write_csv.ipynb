{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Working with CSV Files in Spark DataFrame\n",
    "\n",
    "1. **Read a CSV file into a Spark DataFrame**  \n",
    "2. **Read a CSV file with a user-provided schema**  \n",
    "3. **Read multiple CSV files**  \n",
    "4. **Read all CSV files from a directory**  \n",
    "5. **Options while reading a CSV file**  \n",
    "6. **Write a DataFrame to CSV files**  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://DESKTOP-B3DEEE2:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.2.1</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[3]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>my_spark_app</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x167724c77c0>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# initial setup \n",
    "import time\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = (SparkSession\n",
    "        .builder\n",
    "        .master(\"local[3]\")\n",
    "        .appName(\"my_spark_app\")\n",
    "        .getOrCreate()\n",
    "        )\n",
    "spark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Read a CSV file into a Spark DataFrame** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-----------+---------+---------+---------+--------------------+------------------+--------------------+------------+--------------+------------+-------+--------------------+-----------------+--------------------+----------+-----+--------------------+----------+------------+--------+-----------+-----------------+--------------------+\n",
      "|  _c0|        _c1|      _c2|      _c3|      _c4|                 _c5|               _c6|                 _c7|         _c8|           _c9|        _c10|   _c11|                _c12|             _c13|                _c14|      _c15| _c16|                _c17|      _c18|        _c19|    _c20|       _c21|             _c22|                _c23|\n",
      "+-----+-----------+---------+---------+---------+--------------------+------------------+--------------------+------------+--------------+------------+-------+--------------------+-----------------+--------------------+----------+-----+--------------------+----------+------------+--------+-----------+-----------------+--------------------+\n",
      "|EmpID|  FirstName| LastName|StartDate| ExitDate|               Title|        Supervisor|             ADEmail|BusinessUnit|EmployeeStatus|EmployeeType|PayZone|EmployeeClassific...|   DepartmentType|            Division|       DOB|State|JobFunctionDescri...|GenderCode|LocationCode|RaceDesc|MaritalDesc|Performance Score|Current Employee ...|\n",
      "| 3428|      Paula|    Small|11-Feb-23|     null|Production Techni...|   Renee Mccormick|paula.small@bilea...|          EW|        Active|    Contract| Zone A|           Part-Time|Production       |              Aerial|30-08-1965|   MA|               Labor|      Male|        6593|Hispanic|    Widowed|      Fully Meets|                   3|\n",
      "| 3430|    Michael|  Riordan|21-Jun-21|     null|  Area Sales Manager|    Rebekah Wright|michael.riordan@b...|        CCDR|        Active|    Contract| Zone A|           Full-Time|            Sales|Finance & Accounting|04-04-1998|   ND|               Clerk|      Male|       58782|   Other|     Single|      Fully Meets|                   2|\n",
      "| 3431|    Jasmine|    Onque|29-Jun-19|     null|  Area Sales Manager|         Jason Kim|jasmine.onque@bil...|         TNS|        Active|    Contract| Zone A|           Temporary|            Sales|       General - Con|29-08-1969|   FL|             Laborer|    Female|       33174|   Other|    Married|      Fully Meets|                   3|\n",
      "| 3439|Bartholemew| Khemmich|25-May-22|27-Nov-22|  Area Sales Manager|     Charles Parks|bartholemew.khemm...|          EW|        Active|   Full-Time| Zone A|           Temporary|            Sales|            Splicing|24-11-1981|   CO|             Splicer|      Male|       80820|   Other|     Single|      Fully Meets|                   3|\n",
      "| 3440|       Xana|    Potts|05-Dec-19|17-Feb-23|  Area Sales Manager|    Gregory Walker|xana.potts@bilear...|        CCDR|        Active|    Contract| Zone A|           Full-Time|            Sales|Finance & Accounting|06-11-1951|   KY|          Controller|    Female|       40220|   White|   Divorced|      Fully Meets|                   3|\n",
      "| 3441|     Prater|   Jeremy|28-Apr-19|     null|  Area Sales Manager|       Tyler Lewis|prater.jeremy@bil...|         BPC|        Active|   Part-Time| Zone A|           Part-Time|            Sales|       General - Con|21-11-1989|   NV|             Lineman|      Male|       89139|   Asian|    Widowed|          Exceeds|                   4|\n",
      "| 3442|     Kaylah|     Moon|09-Jul-19|16-Jun-22|  Area Sales Manager|      Ashley Scott|kaylah.moon@bilea...|         PYZ|        Active|   Full-Time| Zone A|           Full-Time|            IT/IS|    Field Operations|24-11-1952|   MA|             Laborer|      Male|        2810|   Black|     Single|          Exceeds|                   2|\n",
      "| 3444|      Bobby|  Rodgers|28-Nov-21|04-Feb-22|  Area Sales Manager|   Matthew Jackson|bobby.rodgers@bil...|         NEL|        Active|    Contract| Zone A|           Part-Time|            Sales|           Engineers|15-11-1983|   KY|            Director|      Male|       44553|   Other|    Widowed|      Fully Meets|                   3|\n",
      "| 3446|     Hector|   Dalton|24-Aug-21|     null|  Area Sales Manager|     Sydney French|hector.dalton@bil...|         BPC|        Active|   Part-Time| Zone A|           Part-Time|            Sales|    Field Operations|01-05-1996|   TX|             Driller|    Female|       16325|   White|   Divorced|          Exceeds|                   2|\n",
      "| 3448|     Angela|   Molina|01-Oct-19|06-Nov-20|  Area Sales Manager|     Patricia Cook|angela.molina@bil...|         SVG|  Future Start|   Full-Time| Zone A|           Temporary|            Sales|           Engineers|12-05-1958|   TX|          Specialist|      Male|       50705|   Asian|    Widowed|      Fully Meets|                   3|\n",
      "| 3452|     Jaydon|Blackburn|08-Nov-22|     null|  Area Sales Manager|     Debbie Crosby|jaydon.blackburn@...|         PYZ|        Active|   Part-Time| Zone A|           Part-Time|            Sales|       General - Con|07-01-1947|   IN|             Foreman|      Male|       12122|   Black|   Divorced|      Fully Meets|                   2|\n",
      "| 3456|       Axel|     Howe|06-Mar-23|     null|  Area Sales Manager|    Martin Hammond|axel.howe@bilearn...|         NEL|        Active|   Full-Time| Zone A|           Temporary|            Sales|    Field Operations|25-09-1946|   KY|          Technician|    Female|       79623|   Black|   Divorced|      Fully Meets|                   3|\n",
      "| 3458|       Cory| Robinson|28-Apr-22|24-May-23|  Area Sales Manager|Elizabeth Anderson|cory.robinson@bil...|         BPC|  Future Start|    Contract| Zone A|           Full-Time|            Sales|    Field Operations|12-08-1996|   TX|             Laborer|    Female|        5194|Hispanic|     Single|Needs Improvement|                   3|\n",
      "| 3459|     Saniya|       Yu|18-Apr-21|21-Jun-22|  Area Sales Manager|       Erin Bailey|saniya.yu@bilearn...|        CCDR|  Future Start|   Part-Time| Zone A|           Full-Time|            Sales|       General - Con|09-02-1944|   TX|             Splicer|      Male|        8779|   Black|    Widowed|          Exceeds|                   2|\n",
      "| 3460|      Alisa|    James|19-Feb-20|     null|  Area Sales Manager|  Dennis Henderson|alisa.james@bilea...|         SVG|        Active|   Full-Time| Zone A|           Full-Time|            Sales|              Aerial|10-02-1944|   TX|             Lineman|      Male|       74682|   Asian|    Married|      Fully Meets|                   3|\n",
      "| 3462|     Aliana|    Nolan|13-Sep-18|17-Sep-21|  Area Sales Manager|   Brianna Mathews|aliana.nolan@bile...|         MSC|        Active|    Contract| Zone A|           Full-Time|            Sales|    Field Operations|09-08-1942|   CO|         Coordinator|      Male|       27270|Hispanic|   Divorced|Needs Improvement|                   3|\n",
      "| 3463|     Kayden|   Dodson|30-Apr-20|18-Jul-21|  Area Sales Manager|    Jessica Peters|kayden.dodson@bil...|         TNS|        Active|   Part-Time| Zone A|           Temporary|            Sales|    Field Operations|21-06-1951|   IN|          Tower Hand|      Male|       12703|Hispanic|     Single|      Fully Meets|                   1|\n",
      "| 3467|      Celia|   Curtis|06-May-20|     null|  Area Sales Manager|  Michael Odonnell|celia.curtis@bile...|         WBL|        Active|    Contract| Zone A|           Part-Time|            Sales|            Fielders|14-05-1987|   KY|            Engineer|    Female|       94333|   Asian|   Divorced|          Exceeds|                   1|\n",
      "| 3473|      Chaim|     Mata|29-Jun-23|     null|  Area Sales Manager|      Desiree Vang|chaim.mata@bilear...|          EW|        Active|   Part-Time| Zone A|           Temporary|            Sales|        Shop (Fleet)|01-10-1950|   CO|             Manager|      Male|       33379|Hispanic|    Widowed|          Exceeds|                   2|\n",
      "+-----+-----------+---------+---------+---------+--------------------+------------------+--------------------+------------+--------------+------------+-------+--------------------+-----------------+--------------------+----------+-----+--------------------+----------+------------+--------+-----------+-----------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = spark.read.csv(\"./source/csv/employee_1.csv\")\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-----------+---------+---------+---------+--------------------+------------------+--------------------+------------+--------------+------------+-------+--------------------+-----------------+--------------------+----------+-----+--------------------+----------+------------+--------+-----------+-----------------+--------------------+\n",
      "|  _c0|        _c1|      _c2|      _c3|      _c4|                 _c5|               _c6|                 _c7|         _c8|           _c9|        _c10|   _c11|                _c12|             _c13|                _c14|      _c15| _c16|                _c17|      _c18|        _c19|    _c20|       _c21|             _c22|                _c23|\n",
      "+-----+-----------+---------+---------+---------+--------------------+------------------+--------------------+------------+--------------+------------+-------+--------------------+-----------------+--------------------+----------+-----+--------------------+----------+------------+--------+-----------+-----------------+--------------------+\n",
      "|EmpID|  FirstName| LastName|StartDate| ExitDate|               Title|        Supervisor|             ADEmail|BusinessUnit|EmployeeStatus|EmployeeType|PayZone|EmployeeClassific...|   DepartmentType|            Division|       DOB|State|JobFunctionDescri...|GenderCode|LocationCode|RaceDesc|MaritalDesc|Performance Score|Current Employee ...|\n",
      "| 3428|      Paula|    Small|11-Feb-23|     null|Production Techni...|   Renee Mccormick|paula.small@bilea...|          EW|        Active|    Contract| Zone A|           Part-Time|Production       |              Aerial|30-08-1965|   MA|               Labor|      Male|        6593|Hispanic|    Widowed|      Fully Meets|                   3|\n",
      "| 3430|    Michael|  Riordan|21-Jun-21|     null|  Area Sales Manager|    Rebekah Wright|michael.riordan@b...|        CCDR|        Active|    Contract| Zone A|           Full-Time|            Sales|Finance & Accounting|04-04-1998|   ND|               Clerk|      Male|       58782|   Other|     Single|      Fully Meets|                   2|\n",
      "| 3431|    Jasmine|    Onque|29-Jun-19|     null|  Area Sales Manager|         Jason Kim|jasmine.onque@bil...|         TNS|        Active|    Contract| Zone A|           Temporary|            Sales|       General - Con|29-08-1969|   FL|             Laborer|    Female|       33174|   Other|    Married|      Fully Meets|                   3|\n",
      "| 3439|Bartholemew| Khemmich|25-May-22|27-Nov-22|  Area Sales Manager|     Charles Parks|bartholemew.khemm...|          EW|        Active|   Full-Time| Zone A|           Temporary|            Sales|            Splicing|24-11-1981|   CO|             Splicer|      Male|       80820|   Other|     Single|      Fully Meets|                   3|\n",
      "| 3440|       Xana|    Potts|05-Dec-19|17-Feb-23|  Area Sales Manager|    Gregory Walker|xana.potts@bilear...|        CCDR|        Active|    Contract| Zone A|           Full-Time|            Sales|Finance & Accounting|06-11-1951|   KY|          Controller|    Female|       40220|   White|   Divorced|      Fully Meets|                   3|\n",
      "| 3441|     Prater|   Jeremy|28-Apr-19|     null|  Area Sales Manager|       Tyler Lewis|prater.jeremy@bil...|         BPC|        Active|   Part-Time| Zone A|           Part-Time|            Sales|       General - Con|21-11-1989|   NV|             Lineman|      Male|       89139|   Asian|    Widowed|          Exceeds|                   4|\n",
      "| 3442|     Kaylah|     Moon|09-Jul-19|16-Jun-22|  Area Sales Manager|      Ashley Scott|kaylah.moon@bilea...|         PYZ|        Active|   Full-Time| Zone A|           Full-Time|            IT/IS|    Field Operations|24-11-1952|   MA|             Laborer|      Male|        2810|   Black|     Single|          Exceeds|                   2|\n",
      "| 3444|      Bobby|  Rodgers|28-Nov-21|04-Feb-22|  Area Sales Manager|   Matthew Jackson|bobby.rodgers@bil...|         NEL|        Active|    Contract| Zone A|           Part-Time|            Sales|           Engineers|15-11-1983|   KY|            Director|      Male|       44553|   Other|    Widowed|      Fully Meets|                   3|\n",
      "| 3446|     Hector|   Dalton|24-Aug-21|     null|  Area Sales Manager|     Sydney French|hector.dalton@bil...|         BPC|        Active|   Part-Time| Zone A|           Part-Time|            Sales|    Field Operations|01-05-1996|   TX|             Driller|    Female|       16325|   White|   Divorced|          Exceeds|                   2|\n",
      "| 3448|     Angela|   Molina|01-Oct-19|06-Nov-20|  Area Sales Manager|     Patricia Cook|angela.molina@bil...|         SVG|  Future Start|   Full-Time| Zone A|           Temporary|            Sales|           Engineers|12-05-1958|   TX|          Specialist|      Male|       50705|   Asian|    Widowed|      Fully Meets|                   3|\n",
      "| 3452|     Jaydon|Blackburn|08-Nov-22|     null|  Area Sales Manager|     Debbie Crosby|jaydon.blackburn@...|         PYZ|        Active|   Part-Time| Zone A|           Part-Time|            Sales|       General - Con|07-01-1947|   IN|             Foreman|      Male|       12122|   Black|   Divorced|      Fully Meets|                   2|\n",
      "| 3456|       Axel|     Howe|06-Mar-23|     null|  Area Sales Manager|    Martin Hammond|axel.howe@bilearn...|         NEL|        Active|   Full-Time| Zone A|           Temporary|            Sales|    Field Operations|25-09-1946|   KY|          Technician|    Female|       79623|   Black|   Divorced|      Fully Meets|                   3|\n",
      "| 3458|       Cory| Robinson|28-Apr-22|24-May-23|  Area Sales Manager|Elizabeth Anderson|cory.robinson@bil...|         BPC|  Future Start|    Contract| Zone A|           Full-Time|            Sales|    Field Operations|12-08-1996|   TX|             Laborer|    Female|        5194|Hispanic|     Single|Needs Improvement|                   3|\n",
      "| 3459|     Saniya|       Yu|18-Apr-21|21-Jun-22|  Area Sales Manager|       Erin Bailey|saniya.yu@bilearn...|        CCDR|  Future Start|   Part-Time| Zone A|           Full-Time|            Sales|       General - Con|09-02-1944|   TX|             Splicer|      Male|        8779|   Black|    Widowed|          Exceeds|                   2|\n",
      "| 3460|      Alisa|    James|19-Feb-20|     null|  Area Sales Manager|  Dennis Henderson|alisa.james@bilea...|         SVG|        Active|   Full-Time| Zone A|           Full-Time|            Sales|              Aerial|10-02-1944|   TX|             Lineman|      Male|       74682|   Asian|    Married|      Fully Meets|                   3|\n",
      "| 3462|     Aliana|    Nolan|13-Sep-18|17-Sep-21|  Area Sales Manager|   Brianna Mathews|aliana.nolan@bile...|         MSC|        Active|    Contract| Zone A|           Full-Time|            Sales|    Field Operations|09-08-1942|   CO|         Coordinator|      Male|       27270|Hispanic|   Divorced|Needs Improvement|                   3|\n",
      "| 3463|     Kayden|   Dodson|30-Apr-20|18-Jul-21|  Area Sales Manager|    Jessica Peters|kayden.dodson@bil...|         TNS|        Active|   Part-Time| Zone A|           Temporary|            Sales|    Field Operations|21-06-1951|   IN|          Tower Hand|      Male|       12703|Hispanic|     Single|      Fully Meets|                   1|\n",
      "| 3467|      Celia|   Curtis|06-May-20|     null|  Area Sales Manager|  Michael Odonnell|celia.curtis@bile...|         WBL|        Active|    Contract| Zone A|           Part-Time|            Sales|            Fielders|14-05-1987|   KY|            Engineer|    Female|       94333|   Asian|   Divorced|          Exceeds|                   1|\n",
      "| 3473|      Chaim|     Mata|29-Jun-23|     null|  Area Sales Manager|      Desiree Vang|chaim.mata@bilear...|          EW|        Active|   Part-Time| Zone A|           Temporary|            Sales|        Shop (Fleet)|01-10-1950|   CO|             Manager|      Male|       33379|Hispanic|    Widowed|          Exceeds|                   2|\n",
      "+-----+-----------+---------+---------+---------+--------------------+------------------+--------------------+------------+--------------+------------+-------+--------------------+-----------------+--------------------+----------+-----+--------------------+----------+------------+--------+-----------+-----------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = spark.read.format(\"csv\").load(\"./source/csv/employee_1.csv\")\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, the `spark` is a SparkSession object. `read` is an object of DataFrameReader class and `csv()` is a method in DataFrameReader.  \n",
    "\n",
    "The above example reads the data into DataFrame column names “_c0” for the first column and “_c1” for the second, and so on. By default, the data type of all these columns would be String.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can check the schema (column_names and Data_type) with help of `printSchema()` method on dataframe  \n",
    "if we didn't specify schema then all columns are string type by default"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- _c0: string (nullable = true)\n",
      " |-- _c1: string (nullable = true)\n",
      " |-- _c2: string (nullable = true)\n",
      " |-- _c3: string (nullable = true)\n",
      " |-- _c4: string (nullable = true)\n",
      " |-- _c5: string (nullable = true)\n",
      " |-- _c6: string (nullable = true)\n",
      " |-- _c7: string (nullable = true)\n",
      " |-- _c8: string (nullable = true)\n",
      " |-- _c9: string (nullable = true)\n",
      " |-- _c10: string (nullable = true)\n",
      " |-- _c11: string (nullable = true)\n",
      " |-- _c12: string (nullable = true)\n",
      " |-- _c13: string (nullable = true)\n",
      " |-- _c14: string (nullable = true)\n",
      " |-- _c15: string (nullable = true)\n",
      " |-- _c16: string (nullable = true)\n",
      " |-- _c17: string (nullable = true)\n",
      " |-- _c18: string (nullable = true)\n",
      " |-- _c19: string (nullable = true)\n",
      " |-- _c20: string (nullable = true)\n",
      " |-- _c21: string (nullable = true)\n",
      " |-- _c22: string (nullable = true)\n",
      " |-- _c23: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using option `header` as `True`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-----------+---------+---------+---------+--------------------+------------------+--------------------+------------+--------------+------------+-------+--------------------------+-----------------+--------------------+----------+-----+----------------------+----------+------------+--------+-----------+-----------------+-----------------------+\n",
      "|EmpID|  FirstName| LastName|StartDate| ExitDate|               Title|        Supervisor|             ADEmail|BusinessUnit|EmployeeStatus|EmployeeType|PayZone|EmployeeClassificationType|   DepartmentType|            Division|       DOB|State|JobFunctionDescription|GenderCode|LocationCode|RaceDesc|MaritalDesc|Performance Score|Current Employee Rating|\n",
      "+-----+-----------+---------+---------+---------+--------------------+------------------+--------------------+------------+--------------+------------+-------+--------------------------+-----------------+--------------------+----------+-----+----------------------+----------+------------+--------+-----------+-----------------+-----------------------+\n",
      "| 3428|      Paula|    Small|11-Feb-23|     null|Production Techni...|   Renee Mccormick|paula.small@bilea...|          EW|        Active|    Contract| Zone A|                 Part-Time|Production       |              Aerial|30-08-1965|   MA|                 Labor|      Male|        6593|Hispanic|    Widowed|      Fully Meets|                      3|\n",
      "| 3430|    Michael|  Riordan|21-Jun-21|     null|  Area Sales Manager|    Rebekah Wright|michael.riordan@b...|        CCDR|        Active|    Contract| Zone A|                 Full-Time|            Sales|Finance & Accounting|04-04-1998|   ND|                 Clerk|      Male|       58782|   Other|     Single|      Fully Meets|                      2|\n",
      "| 3431|    Jasmine|    Onque|29-Jun-19|     null|  Area Sales Manager|         Jason Kim|jasmine.onque@bil...|         TNS|        Active|    Contract| Zone A|                 Temporary|            Sales|       General - Con|29-08-1969|   FL|               Laborer|    Female|       33174|   Other|    Married|      Fully Meets|                      3|\n",
      "| 3439|Bartholemew| Khemmich|25-May-22|27-Nov-22|  Area Sales Manager|     Charles Parks|bartholemew.khemm...|          EW|        Active|   Full-Time| Zone A|                 Temporary|            Sales|            Splicing|24-11-1981|   CO|               Splicer|      Male|       80820|   Other|     Single|      Fully Meets|                      3|\n",
      "| 3440|       Xana|    Potts|05-Dec-19|17-Feb-23|  Area Sales Manager|    Gregory Walker|xana.potts@bilear...|        CCDR|        Active|    Contract| Zone A|                 Full-Time|            Sales|Finance & Accounting|06-11-1951|   KY|            Controller|    Female|       40220|   White|   Divorced|      Fully Meets|                      3|\n",
      "| 3441|     Prater|   Jeremy|28-Apr-19|     null|  Area Sales Manager|       Tyler Lewis|prater.jeremy@bil...|         BPC|        Active|   Part-Time| Zone A|                 Part-Time|            Sales|       General - Con|21-11-1989|   NV|               Lineman|      Male|       89139|   Asian|    Widowed|          Exceeds|                      4|\n",
      "| 3442|     Kaylah|     Moon|09-Jul-19|16-Jun-22|  Area Sales Manager|      Ashley Scott|kaylah.moon@bilea...|         PYZ|        Active|   Full-Time| Zone A|                 Full-Time|            IT/IS|    Field Operations|24-11-1952|   MA|               Laborer|      Male|        2810|   Black|     Single|          Exceeds|                      2|\n",
      "| 3444|      Bobby|  Rodgers|28-Nov-21|04-Feb-22|  Area Sales Manager|   Matthew Jackson|bobby.rodgers@bil...|         NEL|        Active|    Contract| Zone A|                 Part-Time|            Sales|           Engineers|15-11-1983|   KY|              Director|      Male|       44553|   Other|    Widowed|      Fully Meets|                      3|\n",
      "| 3446|     Hector|   Dalton|24-Aug-21|     null|  Area Sales Manager|     Sydney French|hector.dalton@bil...|         BPC|        Active|   Part-Time| Zone A|                 Part-Time|            Sales|    Field Operations|01-05-1996|   TX|               Driller|    Female|       16325|   White|   Divorced|          Exceeds|                      2|\n",
      "| 3448|     Angela|   Molina|01-Oct-19|06-Nov-20|  Area Sales Manager|     Patricia Cook|angela.molina@bil...|         SVG|  Future Start|   Full-Time| Zone A|                 Temporary|            Sales|           Engineers|12-05-1958|   TX|            Specialist|      Male|       50705|   Asian|    Widowed|      Fully Meets|                      3|\n",
      "| 3452|     Jaydon|Blackburn|08-Nov-22|     null|  Area Sales Manager|     Debbie Crosby|jaydon.blackburn@...|         PYZ|        Active|   Part-Time| Zone A|                 Part-Time|            Sales|       General - Con|07-01-1947|   IN|               Foreman|      Male|       12122|   Black|   Divorced|      Fully Meets|                      2|\n",
      "| 3456|       Axel|     Howe|06-Mar-23|     null|  Area Sales Manager|    Martin Hammond|axel.howe@bilearn...|         NEL|        Active|   Full-Time| Zone A|                 Temporary|            Sales|    Field Operations|25-09-1946|   KY|            Technician|    Female|       79623|   Black|   Divorced|      Fully Meets|                      3|\n",
      "| 3458|       Cory| Robinson|28-Apr-22|24-May-23|  Area Sales Manager|Elizabeth Anderson|cory.robinson@bil...|         BPC|  Future Start|    Contract| Zone A|                 Full-Time|            Sales|    Field Operations|12-08-1996|   TX|               Laborer|    Female|        5194|Hispanic|     Single|Needs Improvement|                      3|\n",
      "| 3459|     Saniya|       Yu|18-Apr-21|21-Jun-22|  Area Sales Manager|       Erin Bailey|saniya.yu@bilearn...|        CCDR|  Future Start|   Part-Time| Zone A|                 Full-Time|            Sales|       General - Con|09-02-1944|   TX|               Splicer|      Male|        8779|   Black|    Widowed|          Exceeds|                      2|\n",
      "| 3460|      Alisa|    James|19-Feb-20|     null|  Area Sales Manager|  Dennis Henderson|alisa.james@bilea...|         SVG|        Active|   Full-Time| Zone A|                 Full-Time|            Sales|              Aerial|10-02-1944|   TX|               Lineman|      Male|       74682|   Asian|    Married|      Fully Meets|                      3|\n",
      "| 3462|     Aliana|    Nolan|13-Sep-18|17-Sep-21|  Area Sales Manager|   Brianna Mathews|aliana.nolan@bile...|         MSC|        Active|    Contract| Zone A|                 Full-Time|            Sales|    Field Operations|09-08-1942|   CO|           Coordinator|      Male|       27270|Hispanic|   Divorced|Needs Improvement|                      3|\n",
      "| 3463|     Kayden|   Dodson|30-Apr-20|18-Jul-21|  Area Sales Manager|    Jessica Peters|kayden.dodson@bil...|         TNS|        Active|   Part-Time| Zone A|                 Temporary|            Sales|    Field Operations|21-06-1951|   IN|            Tower Hand|      Male|       12703|Hispanic|     Single|      Fully Meets|                      1|\n",
      "| 3467|      Celia|   Curtis|06-May-20|     null|  Area Sales Manager|  Michael Odonnell|celia.curtis@bile...|         WBL|        Active|    Contract| Zone A|                 Part-Time|            Sales|            Fielders|14-05-1987|   KY|              Engineer|    Female|       94333|   Asian|   Divorced|          Exceeds|                      1|\n",
      "| 3473|      Chaim|     Mata|29-Jun-23|     null|  Area Sales Manager|      Desiree Vang|chaim.mata@bilear...|          EW|        Active|   Part-Time| Zone A|                 Temporary|            Sales|        Shop (Fleet)|01-10-1950|   CO|               Manager|      Male|       33379|Hispanic|    Widowed|          Exceeds|                      2|\n",
      "| 3474|      Arely|   Patton|09-Mar-20|     null|  Area Sales Manager|    Andrew Goodman|arely.patton@bile...|         MSC|        Active|   Full-Time| Zone A|                 Temporary|            Sales|                Catv|16-12-1965|   CO|               Laborer|      Male|       34481|   Other|   Divorced|      Fully Meets|                      2|\n",
      "+-----+-----------+---------+---------+---------+--------------------+------------------+--------------------+------------+--------------+------------+-------+--------------------------+-----------------+--------------------+----------+-----+----------------------+----------+------------+--------+-----------+-----------------+-----------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = (spark.read\n",
    "      .format(\"csv\")\n",
    "      .option(\"header\", True)\n",
    "      .load(\"./source/csv/employee_1.csv\"))\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on method csv in module pyspark.sql.readwriter:\n",
      "\n",
      "csv(path, schema=None, sep=None, encoding=None, quote=None, escape=None, comment=None, header=None, inferSchema=None, ignoreLeadingWhiteSpace=None, ignoreTrailingWhiteSpace=None, nullValue=None, nanValue=None, positiveInf=None, negativeInf=None, dateFormat=None, timestampFormat=None, maxColumns=None, maxCharsPerColumn=None, maxMalformedLogPerPartition=None, mode=None, columnNameOfCorruptRecord=None, multiLine=None, charToEscapeQuoteEscaping=None, samplingRatio=None, enforceSchema=None, emptyValue=None, locale=None, lineSep=None, pathGlobFilter=None, recursiveFileLookup=None, modifiedBefore=None, modifiedAfter=None, unescapedQuoteHandling=None) method of pyspark.sql.readwriter.DataFrameReader instance\n",
      "    Loads a CSV file and returns the result as a  :class:`DataFrame`.\n",
      "    \n",
      "    This function will go through the input once to determine the input schema if\n",
      "    ``inferSchema`` is enabled. To avoid going through the entire data once, disable\n",
      "    ``inferSchema`` option or specify the schema explicitly using ``schema``.\n",
      "    \n",
      "    .. versionadded:: 2.0.0\n",
      "    \n",
      "    Parameters\n",
      "    ----------\n",
      "    path : str or list\n",
      "        string, or list of strings, for input path(s),\n",
      "        or RDD of Strings storing CSV rows.\n",
      "    schema : :class:`pyspark.sql.types.StructType` or str, optional\n",
      "        an optional :class:`pyspark.sql.types.StructType` for the input schema\n",
      "        or a DDL-formatted string (For example ``col0 INT, col1 DOUBLE``).\n",
      "    \n",
      "    Other Parameters\n",
      "    ----------------\n",
      "    Extra options\n",
      "        For the extra options, refer to\n",
      "        `Data Source Option <https://spark.apache.org/docs/latest/sql-data-sources-csv.html#data-source-option>`_\n",
      "        in the version you use.\n",
      "    \n",
      "        .. # noqa\n",
      "    \n",
      "    Examples\n",
      "    --------\n",
      "    >>> df = spark.read.csv('python/test_support/sql/ages.csv')\n",
      "    >>> df.dtypes\n",
      "    [('_c0', 'string'), ('_c1', 'string')]\n",
      "    >>> rdd = sc.textFile('python/test_support/sql/ages.csv')\n",
      "    >>> df2 = spark.read.csv(rdd)\n",
      "    >>> df2.dtypes\n",
      "    [('_c0', 'string'), ('_c1', 'string')]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(spark.read.csv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Read Multipal Csv files  \n",
    "\n",
    "To read multiple CSV files into a PySpark DataFrame, each separated by a comma, you can create a list of file paths and pass it to the spark.read.csv() method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1999"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = (spark.read\n",
    "      .format(\"csv\")\n",
    "      .option(\"header\", True)\n",
    "      .load([\"./source/csv/employee_1.csv\", \"./source/csv/employee_2.csv\"]))\n",
    "df.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Read All csv file from folder\n",
    "\n",
    "To read all CSV files from a directory, specify the directory path as an argument to the csv() method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3000"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = (spark.read\n",
    "      .format(\"csv\")\n",
    "      .option(\"header\", True)\n",
    "      .load(\"./source/csv/\"))\n",
    "df.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We can use wildcard charecter for reading all files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3000"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = (spark.read\n",
    "      .format(\"csv\")\n",
    "      .option(\"header\", True)\n",
    "      .load(\"./source/csv/employee_*.csv\"))\n",
    "df.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Reading CSV files with different options**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3000\n",
      "root\n",
      " |-- EmpID: integer (nullable = true)\n",
      " |-- FirstName: string (nullable = true)\n",
      " |-- LastName: string (nullable = true)\n",
      " |-- StartDate: string (nullable = true)\n",
      " |-- ExitDate: string (nullable = true)\n",
      " |-- Title: string (nullable = true)\n",
      " |-- Supervisor: string (nullable = true)\n",
      " |-- ADEmail: string (nullable = true)\n",
      " |-- BusinessUnit: string (nullable = true)\n",
      " |-- EmployeeStatus: string (nullable = true)\n",
      " |-- EmployeeType: string (nullable = true)\n",
      " |-- PayZone: string (nullable = true)\n",
      " |-- EmployeeClassificationType: string (nullable = true)\n",
      " |-- DepartmentType: string (nullable = true)\n",
      " |-- Division: string (nullable = true)\n",
      " |-- DOB: string (nullable = true)\n",
      " |-- State: string (nullable = true)\n",
      " |-- JobFunctionDescription: string (nullable = true)\n",
      " |-- GenderCode: string (nullable = true)\n",
      " |-- LocationCode: integer (nullable = true)\n",
      " |-- RaceDesc: string (nullable = true)\n",
      " |-- MaritalDesc: string (nullable = true)\n",
      " |-- Performance Score: string (nullable = true)\n",
      " |-- Current Employee Rating: integer (nullable = true)\n",
      "\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "df = (spark.read\n",
    "      .format(\"csv\")\n",
    "      .option(\"header\", True)\n",
    "      .option(\"inferSchema\", True)\n",
    "      .load(\"./source/csv/\"))\n",
    "print(df.count())\n",
    "print(df.printSchema())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "you can chain the option as shown above or you can specify all options at once with `options()` method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3000\n",
      "root\n",
      " |-- EmpID: integer (nullable = true)\n",
      " |-- FirstName: string (nullable = true)\n",
      " |-- LastName: string (nullable = true)\n",
      " |-- StartDate: string (nullable = true)\n",
      " |-- ExitDate: string (nullable = true)\n",
      " |-- Title: string (nullable = true)\n",
      " |-- Supervisor: string (nullable = true)\n",
      " |-- ADEmail: string (nullable = true)\n",
      " |-- BusinessUnit: string (nullable = true)\n",
      " |-- EmployeeStatus: string (nullable = true)\n",
      " |-- EmployeeType: string (nullable = true)\n",
      " |-- PayZone: string (nullable = true)\n",
      " |-- EmployeeClassificationType: string (nullable = true)\n",
      " |-- DepartmentType: string (nullable = true)\n",
      " |-- Division: string (nullable = true)\n",
      " |-- DOB: string (nullable = true)\n",
      " |-- State: string (nullable = true)\n",
      " |-- JobFunctionDescription: string (nullable = true)\n",
      " |-- GenderCode: string (nullable = true)\n",
      " |-- LocationCode: integer (nullable = true)\n",
      " |-- RaceDesc: string (nullable = true)\n",
      " |-- MaritalDesc: string (nullable = true)\n",
      " |-- Performance Score: string (nullable = true)\n",
      " |-- Current Employee Rating: integer (nullable = true)\n",
      "\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "df = (spark.read\n",
    "      .format(\"csv\")\n",
    "      .options(header =True, inferSchema=True)\n",
    "      .load(\"./source/csv/\"))\n",
    "print(df.count())\n",
    "print(df.printSchema())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**most commonly used options are**  \n",
    "\n",
    "| Option       | Description                                                                 |\n",
    "|--------------|-----------------------------------------------------------------------------|\n",
    "| delimiter    | Specifies the character used to separate fields in the CSV file.           |\n",
    "| inferSchema  | Automatically infers the data types of columns based on the file's content.|\n",
    "| header       | Indicates whether the first row of the CSV contains column names.          |\n",
    "| quotes       | Defines the character used for quoting fields containing special characters.|\n",
    "| nullValues   | Specifies the string that represents null or missing values in the data.   |\n",
    "| dateFormat   | Sets the format for parsing date columns in the file.                      |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Read dataframe with custom schema**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.types import StructType, StructField, IntegerType, StringType, DateType\n",
    "\n",
    "schema = StructType([\n",
    "    StructField(\"EmpID\", IntegerType(), True),\n",
    "    StructField(\"FirstName\", StringType(), True),\n",
    "    StructField(\"LastName\", StringType(), True),\n",
    "    StructField(\"StartDate\", StringType(), True),\n",
    "    StructField(\"ExitDate\", StringType(), True),\n",
    "    StructField(\"Title\", StringType(), True),\n",
    "    StructField(\"Supervisor\", StringType(), True),\n",
    "    StructField(\"ADEmail\", StringType(), True),\n",
    "    StructField(\"BusinessUnit\", StringType(), True),\n",
    "    StructField(\"EmployeeStatus\", StringType(), True),\n",
    "    StructField(\"EmployeeType\", StringType(), True),\n",
    "    StructField(\"PayZone\", StringType(), True),\n",
    "    StructField(\"EmployeeClassificationType\", StringType(), True),\n",
    "    StructField(\"DepartmentType\", StringType(), True),\n",
    "    StructField(\"Division\", StringType(), True),\n",
    "    StructField(\"DOB\", StringType(), True),\n",
    "    StructField(\"State\", StringType(), True),\n",
    "    StructField(\"JobFunctionDescription\", StringType(), True),\n",
    "    StructField(\"GenderCode\", StringType(), True),\n",
    "    StructField(\"LocationCode\", IntegerType(), True),\n",
    "    StructField(\"RaceDesc\", StringType(), True),\n",
    "    StructField(\"MaritalDesc\", StringType(), True),\n",
    "    StructField(\"Performance_Score\", StringType(), True),\n",
    "    StructField(\"Current_Employee_Rating\", IntegerType(), True)\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- EmpID: integer (nullable = true)\n",
      " |-- FirstName: string (nullable = true)\n",
      " |-- LastName: string (nullable = true)\n",
      " |-- StartDate: string (nullable = true)\n",
      " |-- ExitDate: string (nullable = true)\n",
      " |-- Title: string (nullable = true)\n",
      " |-- Supervisor: string (nullable = true)\n",
      " |-- ADEmail: string (nullable = true)\n",
      " |-- BusinessUnit: string (nullable = true)\n",
      " |-- EmployeeStatus: string (nullable = true)\n",
      " |-- EmployeeType: string (nullable = true)\n",
      " |-- PayZone: string (nullable = true)\n",
      " |-- EmployeeClassificationType: string (nullable = true)\n",
      " |-- DepartmentType: string (nullable = true)\n",
      " |-- Division: string (nullable = true)\n",
      " |-- DOB: string (nullable = true)\n",
      " |-- State: string (nullable = true)\n",
      " |-- JobFunctionDescription: string (nullable = true)\n",
      " |-- GenderCode: string (nullable = true)\n",
      " |-- LocationCode: integer (nullable = true)\n",
      " |-- RaceDesc: string (nullable = true)\n",
      " |-- MaritalDesc: string (nullable = true)\n",
      " |-- Performance_Score: string (nullable = true)\n",
      " |-- Current_Employee_Rating: integer (nullable = true)\n",
      "\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "df = (spark.read\n",
    "      .format(\"csv\")\n",
    "      .option(\"header\", True)\n",
    "      .schema(schema)\n",
    "      .load(\"./source/csv/\"))\n",
    "print(df.printSchema())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Writing pyspark dataframe to csv**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To write a PySpark DataFrame to a CSV file, you can use the write.csv() method provided by the DataFrame API. This method takes a path as an argument, where the CSV file will be saved. Optionally, you can specify additional parameters such as the delimiter, header inclusion, and whether to overwrite existing files. Here’s how you can do it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "(df.write\n",
    "        .format(\"csv\")\n",
    "        .mode(\"append\")\n",
    "        .option(\"header\",True)\n",
    "        .option(\"delimiter\",'|')\n",
    "        .save(\"./Sinck/csv/employee\"))\n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can specify different saving modes while writing PySpark DataFrame to disk. These saving modes specify how to write a file to disk.\n",
    "\n",
    "`overwrite` – Overwrite the existing file if already exists.\n",
    "\n",
    "`append` – New rows are appended to the existing rows.\n",
    "\n",
    "`ignore` – When this option is used, it ignores the writing operation when the file already exists.\n",
    "\n",
    "`error` – This option returns an error when the file already exists. This is a default option."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
