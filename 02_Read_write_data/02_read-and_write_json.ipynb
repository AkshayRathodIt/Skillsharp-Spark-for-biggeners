{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  **Working with json file in pyspark**\n",
    "\n",
    "1. Reading JSON file in PySpark\n",
    "2. Reading from Multiline JSON File\n",
    "3. Reading from Multiple files at a time\n",
    "4. Reading all files in a directory\n",
    "5. Reading files with a user-specified custom schema\n",
    "6. Reading File using PySpark SQL\n",
    "7. Write PySpark DataFrame to JSON file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "======================================================================================================================================="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading JSON File in PySpark\n",
    "\n",
    "PySpark makes it easy to read JSON files into a DataFrame. The `spark.read.json()` function is used for this purpose.\n",
    "\n",
    "### Steps to Read a JSON File:\n",
    "1. Ensure the JSON file is stored in a path accessible to your Spark session.\n",
    "2. Use `spark.read.json()` to load the JSON file into a DataFrame.\n",
    "\n",
    "### Example Code:\n",
    "```python\n",
    "# Import necessary libraries\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "# Initialize SparkSession\n",
    "spark = SparkSession.builder.appName(\"Read JSON\").getOrCreate()\n",
    "\n",
    "# File path\n",
    "json_file_path = \"path/to/your/jsonfile.json\"\n",
    "\n",
    "# Reading JSON file into DataFrame\n",
    "df = spark.read.json(json_file_path)\n",
    "\n",
    "# Display DataFrame\n",
    "df.show()\n",
    "\n",
    "# Print schema\n",
    "df.printSchema()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://DESKTOP-B3DEEE2:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.2.1</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[3]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>my_spark_app</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x1e008b7f7c0>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# initial setup \n",
    "import time\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = (SparkSession\n",
    "        .builder\n",
    "        .master(\"local[3]\")\n",
    "        .appName(\"my_spark_app\")\n",
    "        .getOrCreate()\n",
    "        )\n",
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+------------+-----------------------+----------+-----------------+--------------------+-----+--------------------------+--------------+------------+---------+-----------+----------+----------------------+---------+------------+-----------+-------+-----------------+--------+---------+-----+------------------+--------------------+\n",
      "|             ADEmail|BusinessUnit|Current Employee Rating|       DOB|   DepartmentType|            Division|EmpID|EmployeeClassificationType|EmployeeStatus|EmployeeType| ExitDate|  FirstName|GenderCode|JobFunctionDescription| LastName|LocationCode|MaritalDesc|PayZone|Performance Score|RaceDesc|StartDate|State|        Supervisor|               Title|\n",
      "+--------------------+------------+-----------------------+----------+-----------------+--------------------+-----+--------------------------+--------------+------------+---------+-----------+----------+----------------------+---------+------------+-----------+-------+-----------------+--------+---------+-----+------------------+--------------------+\n",
      "|paula.small@bilea...|          EW|                      3|30-08-1965|Production       |              Aerial| 3428|                 Part-Time|        Active|    Contract|    \"NaN\"|      Paula|      Male|                 Labor|    Small|        6593|    Widowed| Zone A|      Fully Meets|Hispanic|11-Feb-23|   MA|   Renee Mccormick|Production Techni...|\n",
      "|michael.riordan@b...|        CCDR|                      2|04-04-1998|            Sales|Finance & Accounting| 3430|                 Full-Time|        Active|    Contract|    \"NaN\"|    Michael|      Male|                 Clerk|  Riordan|       58782|     Single| Zone A|      Fully Meets|   Other|21-Jun-21|   ND|    Rebekah Wright|  Area Sales Manager|\n",
      "|jasmine.onque@bil...|         TNS|                      3|29-08-1969|            Sales|       General - Con| 3431|                 Temporary|        Active|    Contract|    \"NaN\"|    Jasmine|    Female|               Laborer|    Onque|       33174|    Married| Zone A|      Fully Meets|   Other|29-Jun-19|   FL|         Jason Kim|  Area Sales Manager|\n",
      "|bartholemew.khemm...|          EW|                      3|24-11-1981|            Sales|            Splicing| 3439|                 Temporary|        Active|   Full-Time|27-Nov-22|Bartholemew|      Male|               Splicer| Khemmich|       80820|     Single| Zone A|      Fully Meets|   Other|25-May-22|   CO|     Charles Parks|  Area Sales Manager|\n",
      "|xana.potts@bilear...|        CCDR|                      3|06-11-1951|            Sales|Finance & Accounting| 3440|                 Full-Time|        Active|    Contract|17-Feb-23|       Xana|    Female|            Controller|    Potts|       40220|   Divorced| Zone A|      Fully Meets|   White|05-Dec-19|   KY|    Gregory Walker|  Area Sales Manager|\n",
      "|prater.jeremy@bil...|         BPC|                      4|21-11-1989|            Sales|       General - Con| 3441|                 Part-Time|        Active|   Part-Time|    \"NaN\"|     Prater|      Male|               Lineman|   Jeremy|       89139|    Widowed| Zone A|          Exceeds|   Asian|28-Apr-19|   NV|       Tyler Lewis|  Area Sales Manager|\n",
      "|kaylah.moon@bilea...|         PYZ|                      2|24-11-1952|            IT/IS|    Field Operations| 3442|                 Full-Time|        Active|   Full-Time|16-Jun-22|     Kaylah|      Male|               Laborer|     Moon|        2810|     Single| Zone A|          Exceeds|   Black|09-Jul-19|   MA|      Ashley Scott|  Area Sales Manager|\n",
      "|bobby.rodgers@bil...|         NEL|                      3|15-11-1983|            Sales|           Engineers| 3444|                 Part-Time|        Active|    Contract|04-Feb-22|      Bobby|      Male|              Director|  Rodgers|       44553|    Widowed| Zone A|      Fully Meets|   Other|28-Nov-21|   KY|   Matthew Jackson|  Area Sales Manager|\n",
      "|hector.dalton@bil...|         BPC|                      2|01-05-1996|            Sales|    Field Operations| 3446|                 Part-Time|        Active|   Part-Time|    \"NaN\"|     Hector|    Female|               Driller|   Dalton|       16325|   Divorced| Zone A|          Exceeds|   White|24-Aug-21|   TX|     Sydney French|  Area Sales Manager|\n",
      "|angela.molina@bil...|         SVG|                      3|12-05-1958|            Sales|           Engineers| 3448|                 Temporary|  Future Start|   Full-Time|06-Nov-20|     Angela|      Male|            Specialist|   Molina|       50705|    Widowed| Zone A|      Fully Meets|   Asian|01-Oct-19|   TX|     Patricia Cook|  Area Sales Manager|\n",
      "|jaydon.blackburn@...|         PYZ|                      2|07-01-1947|            Sales|       General - Con| 3452|                 Part-Time|        Active|   Part-Time|    \"NaN\"|     Jaydon|      Male|               Foreman|Blackburn|       12122|   Divorced| Zone A|      Fully Meets|   Black|08-Nov-22|   IN|     Debbie Crosby|  Area Sales Manager|\n",
      "|axel.howe@bilearn...|         NEL|                      3|25-09-1946|            Sales|    Field Operations| 3456|                 Temporary|        Active|   Full-Time|    \"NaN\"|       Axel|    Female|            Technician|     Howe|       79623|   Divorced| Zone A|      Fully Meets|   Black|06-Mar-23|   KY|    Martin Hammond|  Area Sales Manager|\n",
      "|cory.robinson@bil...|         BPC|                      3|12-08-1996|            Sales|    Field Operations| 3458|                 Full-Time|  Future Start|    Contract|24-May-23|       Cory|    Female|               Laborer| Robinson|        5194|     Single| Zone A|Needs Improvement|Hispanic|28-Apr-22|   TX|Elizabeth Anderson|  Area Sales Manager|\n",
      "|saniya.yu@bilearn...|        CCDR|                      2|09-02-1944|            Sales|       General - Con| 3459|                 Full-Time|  Future Start|   Part-Time|21-Jun-22|     Saniya|      Male|               Splicer|       Yu|        8779|    Widowed| Zone A|          Exceeds|   Black|18-Apr-21|   TX|       Erin Bailey|  Area Sales Manager|\n",
      "|alisa.james@bilea...|         SVG|                      3|10-02-1944|            Sales|              Aerial| 3460|                 Full-Time|        Active|   Full-Time|    \"NaN\"|      Alisa|      Male|               Lineman|    James|       74682|    Married| Zone A|      Fully Meets|   Asian|19-Feb-20|   TX|  Dennis Henderson|  Area Sales Manager|\n",
      "|aliana.nolan@bile...|         MSC|                      3|09-08-1942|            Sales|    Field Operations| 3462|                 Full-Time|        Active|    Contract|17-Sep-21|     Aliana|      Male|           Coordinator|    Nolan|       27270|   Divorced| Zone A|Needs Improvement|Hispanic|13-Sep-18|   CO|   Brianna Mathews|  Area Sales Manager|\n",
      "|kayden.dodson@bil...|         TNS|                      1|21-06-1951|            Sales|    Field Operations| 3463|                 Temporary|        Active|   Part-Time|18-Jul-21|     Kayden|      Male|            Tower Hand|   Dodson|       12703|     Single| Zone A|      Fully Meets|Hispanic|30-Apr-20|   IN|    Jessica Peters|  Area Sales Manager|\n",
      "|celia.curtis@bile...|         WBL|                      1|14-05-1987|            Sales|            Fielders| 3467|                 Part-Time|        Active|    Contract|    \"NaN\"|      Celia|    Female|              Engineer|   Curtis|       94333|   Divorced| Zone A|          Exceeds|   Asian|06-May-20|   KY|  Michael Odonnell|  Area Sales Manager|\n",
      "|chaim.mata@bilear...|          EW|                      2|01-10-1950|            Sales|        Shop (Fleet)| 3473|                 Temporary|        Active|   Part-Time|    \"NaN\"|      Chaim|      Male|               Manager|     Mata|       33379|    Widowed| Zone A|          Exceeds|Hispanic|29-Jun-23|   CO|      Desiree Vang|  Area Sales Manager|\n",
      "|arely.patton@bile...|         MSC|                      2|16-12-1965|            Sales|                Catv| 3474|                 Temporary|        Active|   Full-Time|    \"NaN\"|      Arely|      Male|               Laborer|   Patton|       34481|   Divorced| Zone A|      Fully Meets|   Other|09-Mar-20|   CO|    Andrew Goodman|  Area Sales Manager|\n",
      "+--------------------+------------+-----------------------+----------+-----------------+--------------------+-----+--------------------------+--------------+------------+---------+-----------+----------+----------------------+---------+------------+-----------+-------+-----------------+--------+---------+-----+------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = spark.read.json(\"./source/json/employee_1.json\")\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+------------+-----------------------+----------+-----------------+--------------------+-----+--------------------------+--------------+------------+---------+-----------+----------+----------------------+---------+------------+-----------+-------+-----------------+--------+---------+-----+------------------+--------------------+\n",
      "|             ADEmail|BusinessUnit|Current Employee Rating|       DOB|   DepartmentType|            Division|EmpID|EmployeeClassificationType|EmployeeStatus|EmployeeType| ExitDate|  FirstName|GenderCode|JobFunctionDescription| LastName|LocationCode|MaritalDesc|PayZone|Performance Score|RaceDesc|StartDate|State|        Supervisor|               Title|\n",
      "+--------------------+------------+-----------------------+----------+-----------------+--------------------+-----+--------------------------+--------------+------------+---------+-----------+----------+----------------------+---------+------------+-----------+-------+-----------------+--------+---------+-----+------------------+--------------------+\n",
      "|paula.small@bilea...|          EW|                      3|30-08-1965|Production       |              Aerial| 3428|                 Part-Time|        Active|    Contract|    \"NaN\"|      Paula|      Male|                 Labor|    Small|        6593|    Widowed| Zone A|      Fully Meets|Hispanic|11-Feb-23|   MA|   Renee Mccormick|Production Techni...|\n",
      "|michael.riordan@b...|        CCDR|                      2|04-04-1998|            Sales|Finance & Accounting| 3430|                 Full-Time|        Active|    Contract|    \"NaN\"|    Michael|      Male|                 Clerk|  Riordan|       58782|     Single| Zone A|      Fully Meets|   Other|21-Jun-21|   ND|    Rebekah Wright|  Area Sales Manager|\n",
      "|jasmine.onque@bil...|         TNS|                      3|29-08-1969|            Sales|       General - Con| 3431|                 Temporary|        Active|    Contract|    \"NaN\"|    Jasmine|    Female|               Laborer|    Onque|       33174|    Married| Zone A|      Fully Meets|   Other|29-Jun-19|   FL|         Jason Kim|  Area Sales Manager|\n",
      "|bartholemew.khemm...|          EW|                      3|24-11-1981|            Sales|            Splicing| 3439|                 Temporary|        Active|   Full-Time|27-Nov-22|Bartholemew|      Male|               Splicer| Khemmich|       80820|     Single| Zone A|      Fully Meets|   Other|25-May-22|   CO|     Charles Parks|  Area Sales Manager|\n",
      "|xana.potts@bilear...|        CCDR|                      3|06-11-1951|            Sales|Finance & Accounting| 3440|                 Full-Time|        Active|    Contract|17-Feb-23|       Xana|    Female|            Controller|    Potts|       40220|   Divorced| Zone A|      Fully Meets|   White|05-Dec-19|   KY|    Gregory Walker|  Area Sales Manager|\n",
      "|prater.jeremy@bil...|         BPC|                      4|21-11-1989|            Sales|       General - Con| 3441|                 Part-Time|        Active|   Part-Time|    \"NaN\"|     Prater|      Male|               Lineman|   Jeremy|       89139|    Widowed| Zone A|          Exceeds|   Asian|28-Apr-19|   NV|       Tyler Lewis|  Area Sales Manager|\n",
      "|kaylah.moon@bilea...|         PYZ|                      2|24-11-1952|            IT/IS|    Field Operations| 3442|                 Full-Time|        Active|   Full-Time|16-Jun-22|     Kaylah|      Male|               Laborer|     Moon|        2810|     Single| Zone A|          Exceeds|   Black|09-Jul-19|   MA|      Ashley Scott|  Area Sales Manager|\n",
      "|bobby.rodgers@bil...|         NEL|                      3|15-11-1983|            Sales|           Engineers| 3444|                 Part-Time|        Active|    Contract|04-Feb-22|      Bobby|      Male|              Director|  Rodgers|       44553|    Widowed| Zone A|      Fully Meets|   Other|28-Nov-21|   KY|   Matthew Jackson|  Area Sales Manager|\n",
      "|hector.dalton@bil...|         BPC|                      2|01-05-1996|            Sales|    Field Operations| 3446|                 Part-Time|        Active|   Part-Time|    \"NaN\"|     Hector|    Female|               Driller|   Dalton|       16325|   Divorced| Zone A|          Exceeds|   White|24-Aug-21|   TX|     Sydney French|  Area Sales Manager|\n",
      "|angela.molina@bil...|         SVG|                      3|12-05-1958|            Sales|           Engineers| 3448|                 Temporary|  Future Start|   Full-Time|06-Nov-20|     Angela|      Male|            Specialist|   Molina|       50705|    Widowed| Zone A|      Fully Meets|   Asian|01-Oct-19|   TX|     Patricia Cook|  Area Sales Manager|\n",
      "|jaydon.blackburn@...|         PYZ|                      2|07-01-1947|            Sales|       General - Con| 3452|                 Part-Time|        Active|   Part-Time|    \"NaN\"|     Jaydon|      Male|               Foreman|Blackburn|       12122|   Divorced| Zone A|      Fully Meets|   Black|08-Nov-22|   IN|     Debbie Crosby|  Area Sales Manager|\n",
      "|axel.howe@bilearn...|         NEL|                      3|25-09-1946|            Sales|    Field Operations| 3456|                 Temporary|        Active|   Full-Time|    \"NaN\"|       Axel|    Female|            Technician|     Howe|       79623|   Divorced| Zone A|      Fully Meets|   Black|06-Mar-23|   KY|    Martin Hammond|  Area Sales Manager|\n",
      "|cory.robinson@bil...|         BPC|                      3|12-08-1996|            Sales|    Field Operations| 3458|                 Full-Time|  Future Start|    Contract|24-May-23|       Cory|    Female|               Laborer| Robinson|        5194|     Single| Zone A|Needs Improvement|Hispanic|28-Apr-22|   TX|Elizabeth Anderson|  Area Sales Manager|\n",
      "|saniya.yu@bilearn...|        CCDR|                      2|09-02-1944|            Sales|       General - Con| 3459|                 Full-Time|  Future Start|   Part-Time|21-Jun-22|     Saniya|      Male|               Splicer|       Yu|        8779|    Widowed| Zone A|          Exceeds|   Black|18-Apr-21|   TX|       Erin Bailey|  Area Sales Manager|\n",
      "|alisa.james@bilea...|         SVG|                      3|10-02-1944|            Sales|              Aerial| 3460|                 Full-Time|        Active|   Full-Time|    \"NaN\"|      Alisa|      Male|               Lineman|    James|       74682|    Married| Zone A|      Fully Meets|   Asian|19-Feb-20|   TX|  Dennis Henderson|  Area Sales Manager|\n",
      "|aliana.nolan@bile...|         MSC|                      3|09-08-1942|            Sales|    Field Operations| 3462|                 Full-Time|        Active|    Contract|17-Sep-21|     Aliana|      Male|           Coordinator|    Nolan|       27270|   Divorced| Zone A|Needs Improvement|Hispanic|13-Sep-18|   CO|   Brianna Mathews|  Area Sales Manager|\n",
      "|kayden.dodson@bil...|         TNS|                      1|21-06-1951|            Sales|    Field Operations| 3463|                 Temporary|        Active|   Part-Time|18-Jul-21|     Kayden|      Male|            Tower Hand|   Dodson|       12703|     Single| Zone A|      Fully Meets|Hispanic|30-Apr-20|   IN|    Jessica Peters|  Area Sales Manager|\n",
      "|celia.curtis@bile...|         WBL|                      1|14-05-1987|            Sales|            Fielders| 3467|                 Part-Time|        Active|    Contract|    \"NaN\"|      Celia|    Female|              Engineer|   Curtis|       94333|   Divorced| Zone A|          Exceeds|   Asian|06-May-20|   KY|  Michael Odonnell|  Area Sales Manager|\n",
      "|chaim.mata@bilear...|          EW|                      2|01-10-1950|            Sales|        Shop (Fleet)| 3473|                 Temporary|        Active|   Part-Time|    \"NaN\"|      Chaim|      Male|               Manager|     Mata|       33379|    Widowed| Zone A|          Exceeds|Hispanic|29-Jun-23|   CO|      Desiree Vang|  Area Sales Manager|\n",
      "|arely.patton@bile...|         MSC|                      2|16-12-1965|            Sales|                Catv| 3474|                 Temporary|        Active|   Full-Time|    \"NaN\"|      Arely|      Male|               Laborer|   Patton|       34481|   Divorced| Zone A|      Fully Meets|   Other|09-Mar-20|   CO|    Andrew Goodman|  Area Sales Manager|\n",
      "+--------------------+------------+-----------------------+----------+-----------------+--------------------+-----+--------------------------+--------------+------------+---------+-----------+----------+----------------------+---------+------------+-----------+-------+-----------------+--------+---------+-----+------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = spark.read.format(\"json\").load(\"./source/json/employee_1.json\")\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "======================================================================================================================================="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading from Multiline JSON File in PySpark\n",
    "\n",
    "Multiline JSON files are those where each JSON object spans multiple lines. To read such files, use the `multiline=True` parameter in the `spark.read.json()` method.\n",
    "\n",
    "### Steps to Read a Multiline JSON File:\n",
    "1. Ensure your JSON file contains records in a multiline format.\n",
    "2. Use `spark.read.json()` with the `multiline=True` option.\n",
    "\n",
    "### Example Code:\n",
    "```python\n",
    "# File path\n",
    "multiline_json_file_path = \"path/to/your/multiline_jsonfile.json\"\n",
    "\n",
    "# Reading multiline JSON file into DataFrame\n",
    "df = spark.read.json(multiline_json_file_path, multiline=True)\n",
    "\n",
    "# Display DataFrame\n",
    "df.show()\n",
    "\n",
    "# Print schema\n",
    "df.printSchema()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------------------+--------------------+\n",
      "|  empid|            personal|             profile|\n",
      "+-------+--------------------+--------------------+\n",
      "|SJ011MS|{{New York, 10038...|{Finance, Deputy ...|\n",
      "|MJ012KS|{{Los Angeles, 90...|{Marketing, Senio...|\n",
      "|BK013LP|{{Chicago, 60601,...|{Operations, Dire...|\n",
      "|RJ014MT|{{Austin, 73301, ...|{Human Resources,...|\n",
      "|TM015QP|{{Seattle, 98101,...|     {IT, Team Lead}|\n",
      "|KT016NL|{{Phoenix, 85001,...|{Strategy, Senior...|\n",
      "|SP017JL|{{Denver, 80201, ...|{Sales, Vice Pres...|\n",
      "|LA018GV|{{Atlanta, 30301,...|{Project Manageme...|\n",
      "|MB019WR|{{Dallas, 75201, ...| {Research, Analyst}|\n",
      "|EW020TH|{{Boston, 02108, ...|{Data Science, Da...|\n",
      "|JB021CV|{{San Diego, 9210...|{Logistics, Logis...|\n",
      "|LH022MV|{{Miami, 33101, F...|{Customer Service...|\n",
      "|AB023NF|{{San Francisco, ...|{Infrastructure, ...|\n",
      "|GW024PT|{{Houston, 77001,...|{Administration, ...|\n",
      "|CW025GK|{{Portland, 97201...|{Legal, Legal Adv...|\n",
      "+-------+--------------------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = (spark.read\n",
    "      .format(\"json\")\n",
    "      .option(\"multiline\",True)\n",
    "      .load(\"./source/json/multiline_employee.json\"))\n",
    "\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- empid: string (nullable = true)\n",
      " |-- personal: struct (nullable = true)\n",
      " |    |-- address: struct (nullable = true)\n",
      " |    |    |-- city: string (nullable = true)\n",
      " |    |    |-- postalcode: string (nullable = true)\n",
      " |    |    |-- state: string (nullable = true)\n",
      " |    |    |-- streetaddress: string (nullable = true)\n",
      " |    |-- age: long (nullable = true)\n",
      " |    |-- gender: string (nullable = true)\n",
      " |    |-- name: string (nullable = true)\n",
      " |-- profile: struct (nullable = true)\n",
      " |    |-- department: string (nullable = true)\n",
      " |    |-- designation: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "======================================================================================================================================="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading from Multiple Files at a Time in PySpark\n",
    "\n",
    "PySpark allows reading data from multiple JSON files simultaneously, which is useful for processing large datasets spread across multiple files.\n",
    "\n",
    "### Ways to Read Multiple Files:\n",
    "1. Specify multiple file paths as a list.\n",
    "2. Use wildcard characters to match file patterns in a directory.\n",
    "\n",
    "### Example Code:\n",
    "```python\n",
    "# File paths\n",
    "file_paths = [\"path/to/jsonfile1.json\", \"path/to/jsonfile2.json\"]\n",
    "\n",
    "# Reading multiple JSON files into a single DataFrame\n",
    "df = spark.read.json(file_paths)\n",
    "\n",
    "# Display DataFrame\n",
    "df.show()\n",
    "\n",
    "# Print schema\n",
    "df.printSchema()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1999"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = (spark.read\n",
    "      .format(\"json\")\n",
    "      .load([\"./source/json/employee_1.json\",\"./source/json/employee_2.json\"]))\n",
    "df.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "======================================================================================================================================="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading All Files in a Directory in PySpark\n",
    "\n",
    "PySpark provides a convenient way to read all files from a directory at once, especially useful when dealing with datasets stored across multiple files.\n",
    "\n",
    "### Steps to Read All Files from a Directory:\n",
    "1. Use the `path` to the directory containing JSON files.\n",
    "2. Apply `spark.read.json()` with the directory path to read all files.\n",
    "\n",
    "### Example Code:\n",
    "```python\n",
    "# Directory path containing JSON files\n",
    "directory_path = \"path/to/directory/\"\n",
    "\n",
    "# Reading all JSON files from the directory into a single DataFrame\n",
    "df = spark.read.json(directory_path)\n",
    "\n",
    "# Display DataFrame\n",
    "df.show()\n",
    "\n",
    "# Print schema\n",
    "df.printSchema()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3000"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = (spark.read\n",
    "      .format(\"json\")\n",
    "      .load(\"./source/json/employee_*.json\"))\n",
    "df.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "======================================================================================================================================="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading Files with Custom Schema in PySpark\n",
    "\n",
    "Use a custom schema to handle JSON files with complex or inconsistent structures.\n",
    "\n",
    "### Example:\n",
    "```python\n",
    "from pyspark.sql.types import StructType, StructField, StringType, IntegerType\n",
    "\n",
    "# Define custom schema\n",
    "schema = StructType([\n",
    "    StructField(\"empid\", StringType(), True),\n",
    "    StructField(\"personal\", StructType([\n",
    "        StructField(\"name\", StringType(), True),\n",
    "        StructField(\"gender\", StringType(), True),\n",
    "        StructField(\"age\", IntegerType(), True)\n",
    "    ])),\n",
    "    StructField(\"profile\", StructType([\n",
    "        StructField(\"designation\", StringType(), True),\n",
    "        StructField(\"department\", StringType(), True)\n",
    "    ]))\n",
    "])\n",
    "\n",
    "# Read JSON files with custom schema\n",
    "df = spark.read.json(\"path/to/files\", schema=schema)\n",
    "\n",
    "# Show DataFrame\n",
    "df.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.types import StructType, StructField, IntegerType, StringType, DateType\n",
    "\n",
    "schema = StructType([\n",
    "    StructField(\"EmpID\", IntegerType(), True),\n",
    "    StructField(\"FirstName\", StringType(), True),\n",
    "    StructField(\"LastName\", StringType(), True),\n",
    "    StructField(\"StartDate\", StringType(), True),\n",
    "    StructField(\"ExitDate\", StringType(), True),\n",
    "    StructField(\"Title\", StringType(), True),\n",
    "    StructField(\"Supervisor\", StringType(), True),\n",
    "    StructField(\"ADEmail\", StringType(), True),\n",
    "    StructField(\"BusinessUnit\", StringType(), True),\n",
    "    StructField(\"EmployeeStatus\", StringType(), True),\n",
    "    StructField(\"EmployeeType\", StringType(), True),\n",
    "    StructField(\"PayZone\", StringType(), True),\n",
    "    StructField(\"EmployeeClassificationType\", StringType(), True),\n",
    "    StructField(\"DepartmentType\", StringType(), True),\n",
    "    StructField(\"Division\", StringType(), True),\n",
    "    StructField(\"DOB\", StringType(), True),\n",
    "    StructField(\"State\", StringType(), True),\n",
    "    StructField(\"JobFunctionDescription\", StringType(), True),\n",
    "    StructField(\"GenderCode\", StringType(), True),\n",
    "    StructField(\"LocationCode\", IntegerType(), True),\n",
    "    StructField(\"RaceDesc\", StringType(), True),\n",
    "    StructField(\"MaritalDesc\", StringType(), True),\n",
    "    StructField(\"Performance_Score\", StringType(), True),\n",
    "    StructField(\"Current_Employee_Rating\", IntegerType(), True)\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3000"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = (spark.read\n",
    "      .format(\"json\")\n",
    "      .schema(schema)\n",
    "      .load(\"./source/json/employee_*.json\"))\n",
    "df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- EmpID: integer (nullable = true)\n",
      " |-- FirstName: string (nullable = true)\n",
      " |-- LastName: string (nullable = true)\n",
      " |-- StartDate: string (nullable = true)\n",
      " |-- ExitDate: string (nullable = true)\n",
      " |-- Title: string (nullable = true)\n",
      " |-- Supervisor: string (nullable = true)\n",
      " |-- ADEmail: string (nullable = true)\n",
      " |-- BusinessUnit: string (nullable = true)\n",
      " |-- EmployeeStatus: string (nullable = true)\n",
      " |-- EmployeeType: string (nullable = true)\n",
      " |-- PayZone: string (nullable = true)\n",
      " |-- EmployeeClassificationType: string (nullable = true)\n",
      " |-- DepartmentType: string (nullable = true)\n",
      " |-- Division: string (nullable = true)\n",
      " |-- DOB: string (nullable = true)\n",
      " |-- State: string (nullable = true)\n",
      " |-- JobFunctionDescription: string (nullable = true)\n",
      " |-- GenderCode: string (nullable = true)\n",
      " |-- LocationCode: integer (nullable = true)\n",
      " |-- RaceDesc: string (nullable = true)\n",
      " |-- MaritalDesc: string (nullable = true)\n",
      " |-- Performance_Score: string (nullable = true)\n",
      " |-- Current_Employee_Rating: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "======================================================================================================================================="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading File using PySpark SQL\n",
    "\n",
    "PySpark SQL provides a way to read and query JSON files using SQL queries directly on DataFrames.\n",
    "\n",
    "### Example:\n",
    "```python\n",
    "# SQL approach to read JSON file\n",
    "df = spark.read.format(\"json\").load(\"path/to/jsonfile.json\")\n",
    "\n",
    "# Register as a temporary SQL table\n",
    "df.createOrReplaceTempView(\"json_table\")\n",
    "\n",
    "# Perform SQL queries on the table\n",
    "result = spark.sql(\"SELECT empid, personal.name, profile.designation FROM json_table\")\n",
    "\n",
    "# Show the result\n",
    "result.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+------------+-----------------------+----------+-----------------+--------------------+-----+--------------------------+--------------+------------+---------+-----------+----------+----------------------+---------+------------+-----------+-------+-----------------+--------+---------+-----+------------------+--------------------+\n",
      "|             ADEmail|BusinessUnit|Current Employee Rating|       DOB|   DepartmentType|            Division|EmpID|EmployeeClassificationType|EmployeeStatus|EmployeeType| ExitDate|  FirstName|GenderCode|JobFunctionDescription| LastName|LocationCode|MaritalDesc|PayZone|Performance Score|RaceDesc|StartDate|State|        Supervisor|               Title|\n",
      "+--------------------+------------+-----------------------+----------+-----------------+--------------------+-----+--------------------------+--------------+------------+---------+-----------+----------+----------------------+---------+------------+-----------+-------+-----------------+--------+---------+-----+------------------+--------------------+\n",
      "|paula.small@bilea...|          EW|                      3|30-08-1965|Production       |              Aerial| 3428|                 Part-Time|        Active|    Contract|    \"NaN\"|      Paula|      Male|                 Labor|    Small|        6593|    Widowed| Zone A|      Fully Meets|Hispanic|11-Feb-23|   MA|   Renee Mccormick|Production Techni...|\n",
      "|michael.riordan@b...|        CCDR|                      2|04-04-1998|            Sales|Finance & Accounting| 3430|                 Full-Time|        Active|    Contract|    \"NaN\"|    Michael|      Male|                 Clerk|  Riordan|       58782|     Single| Zone A|      Fully Meets|   Other|21-Jun-21|   ND|    Rebekah Wright|  Area Sales Manager|\n",
      "|jasmine.onque@bil...|         TNS|                      3|29-08-1969|            Sales|       General - Con| 3431|                 Temporary|        Active|    Contract|    \"NaN\"|    Jasmine|    Female|               Laborer|    Onque|       33174|    Married| Zone A|      Fully Meets|   Other|29-Jun-19|   FL|         Jason Kim|  Area Sales Manager|\n",
      "|bartholemew.khemm...|          EW|                      3|24-11-1981|            Sales|            Splicing| 3439|                 Temporary|        Active|   Full-Time|27-Nov-22|Bartholemew|      Male|               Splicer| Khemmich|       80820|     Single| Zone A|      Fully Meets|   Other|25-May-22|   CO|     Charles Parks|  Area Sales Manager|\n",
      "|xana.potts@bilear...|        CCDR|                      3|06-11-1951|            Sales|Finance & Accounting| 3440|                 Full-Time|        Active|    Contract|17-Feb-23|       Xana|    Female|            Controller|    Potts|       40220|   Divorced| Zone A|      Fully Meets|   White|05-Dec-19|   KY|    Gregory Walker|  Area Sales Manager|\n",
      "|prater.jeremy@bil...|         BPC|                      4|21-11-1989|            Sales|       General - Con| 3441|                 Part-Time|        Active|   Part-Time|    \"NaN\"|     Prater|      Male|               Lineman|   Jeremy|       89139|    Widowed| Zone A|          Exceeds|   Asian|28-Apr-19|   NV|       Tyler Lewis|  Area Sales Manager|\n",
      "|kaylah.moon@bilea...|         PYZ|                      2|24-11-1952|            IT/IS|    Field Operations| 3442|                 Full-Time|        Active|   Full-Time|16-Jun-22|     Kaylah|      Male|               Laborer|     Moon|        2810|     Single| Zone A|          Exceeds|   Black|09-Jul-19|   MA|      Ashley Scott|  Area Sales Manager|\n",
      "|bobby.rodgers@bil...|         NEL|                      3|15-11-1983|            Sales|           Engineers| 3444|                 Part-Time|        Active|    Contract|04-Feb-22|      Bobby|      Male|              Director|  Rodgers|       44553|    Widowed| Zone A|      Fully Meets|   Other|28-Nov-21|   KY|   Matthew Jackson|  Area Sales Manager|\n",
      "|hector.dalton@bil...|         BPC|                      2|01-05-1996|            Sales|    Field Operations| 3446|                 Part-Time|        Active|   Part-Time|    \"NaN\"|     Hector|    Female|               Driller|   Dalton|       16325|   Divorced| Zone A|          Exceeds|   White|24-Aug-21|   TX|     Sydney French|  Area Sales Manager|\n",
      "|angela.molina@bil...|         SVG|                      3|12-05-1958|            Sales|           Engineers| 3448|                 Temporary|  Future Start|   Full-Time|06-Nov-20|     Angela|      Male|            Specialist|   Molina|       50705|    Widowed| Zone A|      Fully Meets|   Asian|01-Oct-19|   TX|     Patricia Cook|  Area Sales Manager|\n",
      "|jaydon.blackburn@...|         PYZ|                      2|07-01-1947|            Sales|       General - Con| 3452|                 Part-Time|        Active|   Part-Time|    \"NaN\"|     Jaydon|      Male|               Foreman|Blackburn|       12122|   Divorced| Zone A|      Fully Meets|   Black|08-Nov-22|   IN|     Debbie Crosby|  Area Sales Manager|\n",
      "|axel.howe@bilearn...|         NEL|                      3|25-09-1946|            Sales|    Field Operations| 3456|                 Temporary|        Active|   Full-Time|    \"NaN\"|       Axel|    Female|            Technician|     Howe|       79623|   Divorced| Zone A|      Fully Meets|   Black|06-Mar-23|   KY|    Martin Hammond|  Area Sales Manager|\n",
      "|cory.robinson@bil...|         BPC|                      3|12-08-1996|            Sales|    Field Operations| 3458|                 Full-Time|  Future Start|    Contract|24-May-23|       Cory|    Female|               Laborer| Robinson|        5194|     Single| Zone A|Needs Improvement|Hispanic|28-Apr-22|   TX|Elizabeth Anderson|  Area Sales Manager|\n",
      "|saniya.yu@bilearn...|        CCDR|                      2|09-02-1944|            Sales|       General - Con| 3459|                 Full-Time|  Future Start|   Part-Time|21-Jun-22|     Saniya|      Male|               Splicer|       Yu|        8779|    Widowed| Zone A|          Exceeds|   Black|18-Apr-21|   TX|       Erin Bailey|  Area Sales Manager|\n",
      "|alisa.james@bilea...|         SVG|                      3|10-02-1944|            Sales|              Aerial| 3460|                 Full-Time|        Active|   Full-Time|    \"NaN\"|      Alisa|      Male|               Lineman|    James|       74682|    Married| Zone A|      Fully Meets|   Asian|19-Feb-20|   TX|  Dennis Henderson|  Area Sales Manager|\n",
      "|aliana.nolan@bile...|         MSC|                      3|09-08-1942|            Sales|    Field Operations| 3462|                 Full-Time|        Active|    Contract|17-Sep-21|     Aliana|      Male|           Coordinator|    Nolan|       27270|   Divorced| Zone A|Needs Improvement|Hispanic|13-Sep-18|   CO|   Brianna Mathews|  Area Sales Manager|\n",
      "|kayden.dodson@bil...|         TNS|                      1|21-06-1951|            Sales|    Field Operations| 3463|                 Temporary|        Active|   Part-Time|18-Jul-21|     Kayden|      Male|            Tower Hand|   Dodson|       12703|     Single| Zone A|      Fully Meets|Hispanic|30-Apr-20|   IN|    Jessica Peters|  Area Sales Manager|\n",
      "|celia.curtis@bile...|         WBL|                      1|14-05-1987|            Sales|            Fielders| 3467|                 Part-Time|        Active|    Contract|    \"NaN\"|      Celia|    Female|              Engineer|   Curtis|       94333|   Divorced| Zone A|          Exceeds|   Asian|06-May-20|   KY|  Michael Odonnell|  Area Sales Manager|\n",
      "|chaim.mata@bilear...|          EW|                      2|01-10-1950|            Sales|        Shop (Fleet)| 3473|                 Temporary|        Active|   Part-Time|    \"NaN\"|      Chaim|      Male|               Manager|     Mata|       33379|    Widowed| Zone A|          Exceeds|Hispanic|29-Jun-23|   CO|      Desiree Vang|  Area Sales Manager|\n",
      "|arely.patton@bile...|         MSC|                      2|16-12-1965|            Sales|                Catv| 3474|                 Temporary|        Active|   Full-Time|    \"NaN\"|      Arely|      Male|               Laborer|   Patton|       34481|   Divorced| Zone A|      Fully Meets|   Other|09-Mar-20|   CO|    Andrew Goodman|  Area Sales Manager|\n",
      "+--------------------+------------+-----------------------+----------+-----------------+--------------------+-----+--------------------------+--------------+------------+---------+-----------+----------+----------------------+---------+------------+-----------+-------+-----------------+--------+---------+-----+------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = (spark.sql(\"SELECT * FROM json.`./source/json/employee_1.json`;\"))\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3000"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = (spark.read\n",
    "      .format(\"json\")\n",
    "      .schema(schema)\n",
    "      .load(\"./source/json/employee_*.json\"))\n",
    "df.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "======================================================================================================================================="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Write PySpark DataFrame to JSON File\n",
    "\n",
    "To write a PySpark DataFrame to a JSON file, use the `write` method with the `json` format.\n",
    "\n",
    "### Example:\n",
    "```python\n",
    "# Sample DataFrame\n",
    "data = [(\"SJ011MS\", {\"name\": \"Smith Jones\", \"age\": 28}, {\"designation\": \"Deputy General\", \"department\": \"Finance\"})]\n",
    "df = spark.createDataFrame(data, [\"empid\", \"personal\", \"profile\"])\n",
    "\n",
    "# Write DataFrame to JSON file\n",
    "df.write.json(\"path/to/output.json\")\n",
    "\n",
    "# Optionally, save multiple partitions\n",
    "df.write.json(\"path/to/output/partitioned\", mode=\"overwrite\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.write.format(\"json\").mode(\"overwrite\").save(\"./Sinck/json/employee\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "======================================================================================================================================="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Options while Writing JSON Files\n",
    "\n",
    "When writing a DataFrame to JSON files in PySpark, you can specify various options to control how the files are written. Below are some commonly used options:\n",
    "\n",
    "### 1. `path`\n",
    "- **Description**: Specifies the location where the JSON files will be saved.\n",
    "- **Example**: `df.write.json(\"path/to/output.json\")`\n",
    "\n",
    "---\n",
    "\n",
    "### 2. `mode`\n",
    "- **Description**: Defines the behavior when writing to an existing directory.\n",
    "  - `overwrite`: Overwrites existing files.\n",
    "  - `append`: Appends data to existing files.\n",
    "  - `ignore`: Ignores existing files and doesnâ€™t write the data.\n",
    "- **Example**: `df.write.json(\"path/to/output\", mode=\"overwrite\")`\n",
    "\n",
    "---\n",
    "\n",
    "### 3. `compression`\n",
    "- **Description**: Specifies the compression codec to use when writing the JSON files (e.g., \"gzip\", \"snappy\").\n",
    "- **Example**: `df.write.json(\"path/to/output.json\", compression=\"gzip\")`\n",
    "\n",
    "---\n",
    "\n",
    "### 4. `dateFormat`\n",
    "- **Description**: Specifies the format for date columns when writing JSON files.\n",
    "- **Example**: `df.write.json(\"path/to/output.json\", dateFormat=\"yyyy-MM-dd\")`\n",
    "\n",
    "---\n",
    "\n",
    "### 5. `timestampFormat`\n",
    "- **Description**: Specifies the format for timestamp columns when writing JSON files.\n",
    "- **Example**: `df.write.json(\"path/to/output.json\", timestampFormat=\"yyyy-MM-dd HH:mm:ss\")`\n",
    "\n",
    "---\n",
    "\n",
    "### 6. `lineSep`\n",
    "- **Description**: Specifies the character sequence to use as a line separator between JSON objects.\n",
    "- **Example**: `df.write.json(\"path/to/output.json\", lineSep=\"\\n\")`\n",
    "\n",
    "---\n",
    "\n",
    "### 7. `encoding`\n",
    "- **Description**: Specifies the character encoding to use when writing the JSON files.\n",
    "- **Example**: `df.write.json(\"path/to/output.json\", encoding=\"utf-8\")`\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
